<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.6"/>
<title>FFNN: ffnn::optimizer::GradientDescent_&lt; LayerType, LossFn &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">FFNN
   &#160;<span id="projectnumber">0.0.1</span>
   </div>
   <div id="projectbrief">Fupa-funtime neural nets: a header-only neural network library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.6 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="inherits.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(10)"><span class="SelectionMark">&#160;</span>Macros</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(11)"><span class="SelectionMark">&#160;</span>Groups</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceffnn.html">ffnn</a></li><li class="navelem"><a class="el" href="namespaceffnn_1_1optimizer.html">optimizer</a></li><li class="navelem"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">GradientDescent_</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="classffnn_1_1optimizer_1_1_gradient_descent__-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">ffnn::optimizer::GradientDescent_&lt; LayerType, LossFn &gt; Class Template Reference<span class="mlabels"><span class="mlabel">abstract</span></span></div>  </div>
</div><!--header-->
<div class="contents">

<p><code>#include &quot;<a class="el" href="fwd_8h_source.html">fwd.h</a>&quot;</code></p>
<div class="dynheader">
Inheritance diagram for ffnn::optimizer::GradientDescent_&lt; LayerType, LossFn &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="classffnn_1_1optimizer_1_1_gradient_descent____inherit__graph.png" border="0" usemap="#ffnn_1_1optimizer_1_1_gradient_descent___3_01_layer_type_00_01_loss_fn_01_4_inherit__map" alt="Inheritance graph"/></div>
<map name="ffnn_1_1optimizer_1_1_gradient_descent___3_01_layer_type_00_01_loss_fn_01_4_inherit__map" id="ffnn_1_1optimizer_1_1_gradient_descent___3_01_layer_type_00_01_loss_fn_01_4_inherit__map">
<area shape="rect" id="node2" href="classffnn_1_1optimizer_1_1_optimizer.html" title="A layer&#45;wise optimizer visitor. " alt="" coords="27,6,196,47"/></map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for ffnn::optimizer::GradientDescent_&lt; LayerType, LossFn &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="classffnn_1_1optimizer_1_1_gradient_descent____coll__graph.png" border="0" usemap="#ffnn_1_1optimizer_1_1_gradient_descent___3_01_layer_type_00_01_loss_fn_01_4_coll__map" alt="Collaboration graph"/></div>
<map name="ffnn_1_1optimizer_1_1_gradient_descent___3_01_layer_type_00_01_loss_fn_01_4_coll__map" id="ffnn_1_1optimizer_1_1_gradient_descent___3_01_layer_type_00_01_loss_fn_01_4_coll__map">
<area shape="rect" id="node2" href="classffnn_1_1optimizer_1_1_optimizer.html" title="A layer&#45;wise optimizer visitor. " alt="" coords="27,6,196,47"/></map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:a0d078c334d4cdebc587ac45ceb16cf8c"><td class="memItemLeft" align="right" valign="top">typedef <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html">Optimizer</a>&lt; LayerType &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a0d078c334d4cdebc587ac45ceb16cf8c">BaseType</a></td></tr>
<tr class="memdesc:a0d078c334d4cdebc587ac45ceb16cf8c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Base type standardization.  <a href="#a0d078c334d4cdebc587ac45ceb16cf8c">More...</a><br/></td></tr>
<tr class="separator:a0d078c334d4cdebc587ac45ceb16cf8c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ea42179033176eb7686e00769034c8a"><td class="memItemLeft" align="right" valign="top">typedef <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#acaa42e2661559c561caf881c4d934b8c">BaseType::Scalar</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a9ea42179033176eb7686e00769034c8a">Scalar</a></td></tr>
<tr class="memdesc:a9ea42179033176eb7686e00769034c8a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Scalar type standardization.  <a href="#a9ea42179033176eb7686e00769034c8a">More...</a><br/></td></tr>
<tr class="separator:a9ea42179033176eb7686e00769034c8a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4870280152e25bf9a7622d52fa889b06"><td class="memItemLeft" align="right" valign="top">typedef LayerType::InputBlockType&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a4870280152e25bf9a7622d52fa889b06">InputBlockType</a></td></tr>
<tr class="memdesc:a4870280152e25bf9a7622d52fa889b06"><td class="mdescLeft">&#160;</td><td class="mdescRight">Matrix type standardization.  <a href="#a4870280152e25bf9a7622d52fa889b06">More...</a><br/></td></tr>
<tr class="separator:a4870280152e25bf9a7622d52fa889b06"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5ad0804c042e40a0a0ac64ae34fdc85"><td class="memItemLeft" align="right" valign="top">typedef LayerType::ParametersType&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#ae5ad0804c042e40a0a0ac64ae34fdc85">ParametersType</a></td></tr>
<tr class="memdesc:ae5ad0804c042e40a0a0ac64ae34fdc85"><td class="mdescLeft">&#160;</td><td class="mdescRight">Matrix type standardization.  <a href="#ae5ad0804c042e40a0a0ac64ae34fdc85">More...</a><br/></td></tr>
<tr class="separator:ae5ad0804c042e40a0a0ac64ae34fdc85"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_types_classffnn_1_1optimizer_1_1_optimizer"><td colspan="2" onclick="javascript:toggleInherit('pub_types_classffnn_1_1optimizer_1_1_optimizer')"><img src="closed.png" alt="-"/>&#160;Public Types inherited from <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html">ffnn::optimizer::Optimizer&lt; LayerType &gt;</a></td></tr>
<tr class="memitem:ac03e7181934bf0c12a97fc67a60484ab inherit pub_types_classffnn_1_1optimizer_1_1_optimizer"><td class="memItemLeft" align="right" valign="top">typedef boost::shared_ptr<br class="typebreak"/>
&lt; <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html">Optimizer</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#ac03e7181934bf0c12a97fc67a60484ab">Ptr</a></td></tr>
<tr class="memdesc:ac03e7181934bf0c12a97fc67a60484ab inherit pub_types_classffnn_1_1optimizer_1_1_optimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Shared resource standardization.  <a href="#ac03e7181934bf0c12a97fc67a60484ab">More...</a><br/></td></tr>
<tr class="separator:ac03e7181934bf0c12a97fc67a60484ab inherit pub_types_classffnn_1_1optimizer_1_1_optimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d62c55f6f830e993ffe801fb17a1c3a inherit pub_types_classffnn_1_1optimizer_1_1_optimizer"><td class="memItemLeft" align="right" valign="top">typedef boost::shared_ptr<br class="typebreak"/>
&lt; const <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html">Optimizer</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a5d62c55f6f830e993ffe801fb17a1c3a">ConstPtr</a></td></tr>
<tr class="memdesc:a5d62c55f6f830e993ffe801fb17a1c3a inherit pub_types_classffnn_1_1optimizer_1_1_optimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constant shared resource standardization.  <a href="#a5d62c55f6f830e993ffe801fb17a1c3a">More...</a><br/></td></tr>
<tr class="separator:a5d62c55f6f830e993ffe801fb17a1c3a inherit pub_types_classffnn_1_1optimizer_1_1_optimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acaa42e2661559c561caf881c4d934b8c inherit pub_types_classffnn_1_1optimizer_1_1_optimizer"><td class="memItemLeft" align="right" valign="top">typedef LayerType::Scalar&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#acaa42e2661559c561caf881c4d934b8c">Scalar</a></td></tr>
<tr class="memdesc:acaa42e2661559c561caf881c4d934b8c inherit pub_types_classffnn_1_1optimizer_1_1_optimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Scalar type standardization.  <a href="#acaa42e2661559c561caf881c4d934b8c">More...</a><br/></td></tr>
<tr class="separator:acaa42e2661559c561caf881c4d934b8c inherit pub_types_classffnn_1_1optimizer_1_1_optimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ae6b884c98e7e5eadaac0f7c88d5a2cc1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#ae6b884c98e7e5eadaac0f7c88d5a2cc1">GradientDescent_</a> (<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a9ea42179033176eb7686e00769034c8a">Scalar</a> lr)</td></tr>
<tr class="memdesc:ae6b884c98e7e5eadaac0f7c88d5a2cc1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Setup constructor.  <a href="#ae6b884c98e7e5eadaac0f7c88d5a2cc1">More...</a><br/></td></tr>
<tr class="separator:ae6b884c98e7e5eadaac0f7c88d5a2cc1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a56014df7a5afe715fb041bb0d629f15a"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a56014df7a5afe715fb041bb0d629f15a">~GradientDescent_</a> ()</td></tr>
<tr class="separator:a56014df7a5afe715fb041bb0d629f15a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9b2a8f8c1a1411ffb3b2d207c42fca9e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a9b2a8f8c1a1411ffb3b2d207c42fca9e">initialize</a> (LayerType &amp;layer)</td></tr>
<tr class="memdesc:a9b2a8f8c1a1411ffb3b2d207c42fca9e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initializes the <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html" title="A layer-wise optimizer visitor. ">Optimizer</a>.  <a href="#a9b2a8f8c1a1411ffb3b2d207c42fca9e">More...</a><br/></td></tr>
<tr class="separator:a9b2a8f8c1a1411ffb3b2d207c42fca9e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50581919467a4bb592eeb7fa98cd3b34"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a50581919467a4bb592eeb7fa98cd3b34">reset</a> (LayerType &amp;layer)</td></tr>
<tr class="memdesc:a50581919467a4bb592eeb7fa98cd3b34"><td class="mdescLeft">&#160;</td><td class="mdescRight">Resets persistent <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html" title="A layer-wise optimizer visitor. ">Optimizer</a> states.  <a href="#a50581919467a4bb592eeb7fa98cd3b34">More...</a><br/></td></tr>
<tr class="separator:a50581919467a4bb592eeb7fa98cd3b34"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3fda5e93b5fc359c4e36fc1c681e6929"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a3fda5e93b5fc359c4e36fc1c681e6929">forward</a> (LayerType &amp;layer)</td></tr>
<tr class="memdesc:a3fda5e93b5fc359c4e36fc1c681e6929"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes one forward optimization update step.  <a href="#a3fda5e93b5fc359c4e36fc1c681e6929">More...</a><br/></td></tr>
<tr class="separator:a3fda5e93b5fc359c4e36fc1c681e6929"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a810bd29432c41b39239337139b7a0a0b"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a810bd29432c41b39239337139b7a0a0b">backward</a> (LayerType &amp;layer)=0</td></tr>
<tr class="memdesc:a810bd29432c41b39239337139b7a0a0b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes optimization step during backward propogation.  <a href="#a810bd29432c41b39239337139b7a0a0b">More...</a><br/></td></tr>
<tr class="separator:a810bd29432c41b39239337139b7a0a0b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a90fface371af7bef89880d278a9b2007"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a90fface371af7bef89880d278a9b2007">update</a> (LayerType &amp;layer)</td></tr>
<tr class="memdesc:a90fface371af7bef89880d278a9b2007"><td class="mdescLeft">&#160;</td><td class="mdescRight">Applies optimization update.  <a href="#a90fface371af7bef89880d278a9b2007">More...</a><br/></td></tr>
<tr class="separator:a90fface371af7bef89880d278a9b2007"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classffnn_1_1optimizer_1_1_optimizer')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html">ffnn::optimizer::Optimizer&lt; LayerType &gt;</a></td></tr>
<tr class="memitem:a5daf7f0191df7c672247e0d5a25fbafa inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a5daf7f0191df7c672247e0d5a25fbafa">Optimizer</a> (const std::string &amp;<a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a9c472d1e2ef75decdae1cf2db7582582">name</a>)</td></tr>
<tr class="memdesc:a5daf7f0191df7c672247e0d5a25fbafa inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Naming constructor.  <a href="#a5daf7f0191df7c672247e0d5a25fbafa">More...</a><br/></td></tr>
<tr class="separator:a5daf7f0191df7c672247e0d5a25fbafa inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad16c1cab142fcc9542da0ef98df75f47 inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#ad16c1cab142fcc9542da0ef98df75f47">~Optimizer</a> ()</td></tr>
<tr class="separator:ad16c1cab142fcc9542da0ef98df75f47 inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c472d1e2ef75decdae1cf2db7582582 inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memItemLeft" align="right" valign="top">const std::string &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a9c472d1e2ef75decdae1cf2db7582582">name</a> () const </td></tr>
<tr class="memdesc:a9c472d1e2ef75decdae1cf2db7582582 inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Exposes name of the optimizer.  <a href="#a9c472d1e2ef75decdae1cf2db7582582">More...</a><br/></td></tr>
<tr class="separator:a9c472d1e2ef75decdae1cf2db7582582 inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9aa028897eed9617b6439e1ea56a1ee inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#ab9aa028897eed9617b6439e1ea56a1ee">setName</a> (const std::string &amp;<a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a9c472d1e2ef75decdae1cf2db7582582">name</a>)</td></tr>
<tr class="memdesc:ab9aa028897eed9617b6439e1ea56a1ee inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets name of the optimizer.  <a href="#ab9aa028897eed9617b6439e1ea56a1ee">More...</a><br/></td></tr>
<tr class="separator:ab9aa028897eed9617b6439e1ea56a1ee inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a600bd6a5552e490da1b230c67a5e67d6"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a9ea42179033176eb7686e00769034c8a">Scalar</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a600bd6a5552e490da1b230c67a5e67d6">lr_</a></td></tr>
<tr class="memdesc:a600bd6a5552e490da1b230c67a5e67d6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Learning rate.  <a href="#a600bd6a5552e490da1b230c67a5e67d6">More...</a><br/></td></tr>
<tr class="separator:a600bd6a5552e490da1b230c67a5e67d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a51e6729537c7de173ea53a27965415"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a4870280152e25bf9a7622d52fa889b06">InputBlockType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a6a51e6729537c7de173ea53a27965415">prev_input_</a></td></tr>
<tr class="memdesc:a6a51e6729537c7de173ea53a27965415"><td class="mdescLeft">&#160;</td><td class="mdescRight">Previous input.  <a href="#a6a51e6729537c7de173ea53a27965415">More...</a><br/></td></tr>
<tr class="separator:a6a51e6729537c7de173ea53a27965415"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a47f75b7c806bdd2bd254c147a35e3ae2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#ae5ad0804c042e40a0a0ac64ae34fdc85">ParametersType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a47f75b7c806bdd2bd254c147a35e3ae2">gradient_</a></td></tr>
<tr class="memdesc:a47f75b7c806bdd2bd254c147a35e3ae2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Coefficient gradient.  <a href="#a47f75b7c806bdd2bd254c147a35e3ae2">More...</a><br/></td></tr>
<tr class="separator:a47f75b7c806bdd2bd254c147a35e3ae2"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Member Typedef Documentation</h2>
<a class="anchor" id="a0d078c334d4cdebc587ac45ceb16cf8c"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename LayerType, LossFunction LossFn&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">typedef <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html">Optimizer</a>&lt;LayerType&gt; <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">ffnn::optimizer::GradientDescent_</a>&lt; LayerType, LossFn &gt;::<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a0d078c334d4cdebc587ac45ceb16cf8c">BaseType</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Base type standardization. </p>

</div>
</div>
<a class="anchor" id="a4870280152e25bf9a7622d52fa889b06"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename LayerType, LossFunction LossFn&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">typedef LayerType::InputBlockType <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">ffnn::optimizer::GradientDescent_</a>&lt; LayerType, LossFn &gt;::<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a4870280152e25bf9a7622d52fa889b06">InputBlockType</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Matrix type standardization. </p>

</div>
</div>
<a class="anchor" id="ae5ad0804c042e40a0a0ac64ae34fdc85"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename LayerType, LossFunction LossFn&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">typedef LayerType::ParametersType <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">ffnn::optimizer::GradientDescent_</a>&lt; LayerType, LossFn &gt;::<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#ae5ad0804c042e40a0a0ac64ae34fdc85">ParametersType</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Matrix type standardization. </p>

</div>
</div>
<a class="anchor" id="a9ea42179033176eb7686e00769034c8a"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename LayerType, LossFunction LossFn&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">typedef <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#acaa42e2661559c561caf881c4d934b8c">BaseType::Scalar</a> <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">ffnn::optimizer::GradientDescent_</a>&lt; LayerType, LossFn &gt;::<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a9ea42179033176eb7686e00769034c8a">Scalar</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Scalar type standardization. </p>

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a class="anchor" id="ae6b884c98e7e5eadaac0f7c88d5a2cc1"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename LayerType , LossFunction LossFn&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">ffnn::optimizer::GradientDescent_</a>&lt; LayerType, LossFn &gt;::<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">GradientDescent_</a> </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a9ea42179033176eb7686e00769034c8a">Scalar</a>&#160;</td>
          <td class="paramname"><em>lr</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">explicit</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Setup constructor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">lr</td><td>Learning rate </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a56014df7a5afe715fb041bb0d629f15a"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename LayerType, LossFunction LossFn&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">ffnn::optimizer::GradientDescent_</a>&lt; LayerType, LossFn &gt;::~<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">GradientDescent_</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a class="anchor" id="a810bd29432c41b39239337139b7a0a0b"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename LayerType, LossFunction LossFn&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">ffnn::optimizer::GradientDescent_</a>&lt; LayerType, LossFn &gt;::backward </td>
          <td>(</td>
          <td class="paramtype">LayerType &amp;&#160;</td>
          <td class="paramname"><em>layer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes optimization step during backward propogation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">layer</td><td>Layer to optimize </td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">true</td><td>if optimization setup was successful </td></tr>
    <tr><td class="paramname">false</td><td>otherwise </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#ab1f9b1cae01f93f53ecf7119bedb6369">ffnn::optimizer::Optimizer&lt; LayerType &gt;</a>.</p>

</div>
</div>
<a class="anchor" id="a3fda5e93b5fc359c4e36fc1c681e6929"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename LayerType, LossFunction LossFn&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">ffnn::optimizer::GradientDescent_</a>&lt; LayerType, LossFn &gt;::forward </td>
          <td>(</td>
          <td class="paramtype">LayerType &amp;&#160;</td>
          <td class="paramname"><em>layer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes one forward optimization update step. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">layer</td><td>Layer to optimize </td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">true</td><td>if optimization setup was successful </td></tr>
    <tr><td class="paramname">false</td><td>otherwise </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a80505cfdeba0a3c8d1db19a2821613f2">ffnn::optimizer::Optimizer&lt; LayerType &gt;</a>.</p>

</div>
</div>
<a class="anchor" id="a9b2a8f8c1a1411ffb3b2d207c42fca9e"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename LayerType, LossFunction LossFn&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">ffnn::optimizer::GradientDescent_</a>&lt; LayerType, LossFn &gt;::initialize </td>
          <td>(</td>
          <td class="paramtype">LayerType &amp;&#160;</td>
          <td class="paramname"><em>layer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Initializes the <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html" title="A layer-wise optimizer visitor. ">Optimizer</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">layer</td><td>Layer to optimize </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a4302b66ba9b013ae4833eca235ff306a">ffnn::optimizer::Optimizer&lt; LayerType &gt;</a>.</p>

</div>
</div>
<a class="anchor" id="a50581919467a4bb592eeb7fa98cd3b34"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename LayerType, LossFunction LossFn&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">ffnn::optimizer::GradientDescent_</a>&lt; LayerType, LossFn &gt;::reset </td>
          <td>(</td>
          <td class="paramtype">LayerType &amp;&#160;</td>
          <td class="paramname"><em>layer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Resets persistent <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html" title="A layer-wise optimizer visitor. ">Optimizer</a> states. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">layer</td><td>Layer to optimize </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#ade04e7582eb7b833713a9bd33e0e8346">ffnn::optimizer::Optimizer&lt; LayerType &gt;</a>.</p>

</div>
</div>
<a class="anchor" id="a90fface371af7bef89880d278a9b2007"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename LayerType, LossFunction LossFn&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">ffnn::optimizer::GradientDescent_</a>&lt; LayerType, LossFn &gt;::update </td>
          <td>(</td>
          <td class="paramtype">LayerType &amp;&#160;</td>
          <td class="paramname"><em>layer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Applies optimization update. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">layer</td><td>Layer to optimize </td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">true</td><td>if optimization update was applied successfully </td></tr>
    <tr><td class="paramname">false</td><td>otherwise </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a7c88c2794446e03ccd41628bb25d7a07">ffnn::optimizer::Optimizer&lt; LayerType &gt;</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a class="anchor" id="a47f75b7c806bdd2bd254c147a35e3ae2"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename LayerType, LossFunction LossFn&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#ae5ad0804c042e40a0a0ac64ae34fdc85">ParametersType</a> <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">ffnn::optimizer::GradientDescent_</a>&lt; LayerType, LossFn &gt;::gradient_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Coefficient gradient. </p>

</div>
</div>
<a class="anchor" id="a600bd6a5552e490da1b230c67a5e67d6"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename LayerType, LossFunction LossFn&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a9ea42179033176eb7686e00769034c8a">Scalar</a> <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">ffnn::optimizer::GradientDescent_</a>&lt; LayerType, LossFn &gt;::lr_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Learning rate. </p>

</div>
</div>
<a class="anchor" id="a6a51e6729537c7de173ea53a27965415"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename LayerType, LossFunction LossFn&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html#a4870280152e25bf9a7622d52fa889b06">InputBlockType</a> <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent__.html">ffnn::optimizer::GradientDescent_</a>&lt; LayerType, LossFn &gt;::prev_input_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Previous input. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>/home/briancairl/packages/src/ffnn-cpp/ffnn/include/ffnn/optimizer/<a class="el" href="fwd_8h_source.html">fwd.h</a></li>
<li>/home/briancairl/packages/src/ffnn-cpp/ffnn/include/ffnn/optimizer/<a class="el" href="gradient__descent_8h_source.html">gradient_descent.h</a></li>
<li>/home/briancairl/packages/src/ffnn-cpp/ffnn/include/ffnn/impl/optimizer/gradient_descent/<a class="el" href="gradient__descent_8hpp_source.html">gradient_descent.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Thu Jun 8 2017 01:08:57 for FFNN by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.6
</small></address>
</body>
</html>
