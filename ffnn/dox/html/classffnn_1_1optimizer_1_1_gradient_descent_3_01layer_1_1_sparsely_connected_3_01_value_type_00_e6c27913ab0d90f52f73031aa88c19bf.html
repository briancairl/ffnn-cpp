<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.6"/>
<title>FFNN: ffnn::optimizer::GradientDescent&lt; layer::SparselyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">FFNN
   &#160;<span id="projectnumber">0.0.1</span>
   </div>
   <div id="projectbrief">Fupa-funtime neural nets: a header-only neural network library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.6 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="inherits.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(10)"><span class="SelectionMark">&#160;</span>Macros</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(11)"><span class="SelectionMark">&#160;</span>Groups</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceffnn.html">ffnn</a></li><li class="navelem"><a class="el" href="namespaceffnn_1_1optimizer.html">optimizer</a></li><li class="navelem"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html">GradientDescent< layer::SparselyConnected< ValueType, InputsAtCompileTime, OutputsAtCompileTime > ></a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_dcf78478649d1e847aa817a2db3befcd.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">ffnn::optimizer::GradientDescent&lt; layer::SparselyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><code>#include &quot;<a class="el" href="optimizer_2impl_2gradient__descent_2sparsely__connected_8hpp_source.html">sparsely_connected.hpp</a>&quot;</code></p>
<div class="dynheader">
Inheritance diagram for ffnn::optimizer::GradientDescent&lt; layer::SparselyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_cd778e175158c5a4356ddedca0ec7368.png" border="0" usemap="#ffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_01_inputs_at_compile_time_00_01_outputs_at_compile_time_01_4_01_4_inherit__map" alt="Inheritance graph"/></div>
<map name="ffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_01_inputs_at_compile_time_00_01_outputs_at_compile_time_01_4_01_4_inherit__map" id="ffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_01_inputs_at_compile_time_00_01_outputs_at_compile_time_01_4_01_4_inherit__map">
<area shape="rect" id="node3" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_sparsely_connected_3_01_value_type_00_01_inputs_at5101e46d32858ec2169acdeede08d723.html" title="ffnn::optimizer::Adam\l\&lt; layer::SparselyConnected\l\&lt; ValueType, InputsAtCompileTime,\l OutputsAtCompileTime \&gt; \&gt;" alt="" coords="571,5,805,75"/><area shape="rect" id="node2" href="classffnn_1_1optimizer_1_1_optimizer.html" title="ffnn::optimizer::Optimizer\l\&lt; layer::SparselyConnected\l\&lt; ValueType, InputsAtCompileTime,\l OutputsAtCompileTime \&gt; \&gt;" alt="" coords="5,5,240,75"/></map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for ffnn::optimizer::GradientDescent&lt; layer::SparselyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_6ef3327b68786a574793ed94879a29cc.png" border="0" usemap="#ffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_01_inputs_at_compile_time_00_01_outputs_at_compile_time_01_4_01_4_coll__map" alt="Collaboration graph"/></div>
<map name="ffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_01_inputs_at_compile_time_00_01_outputs_at_compile_time_01_4_01_4_coll__map" id="ffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_01_inputs_at_compile_time_00_01_outputs_at_compile_time_01_4_01_4_coll__map">
<area shape="rect" id="node2" href="classffnn_1_1optimizer_1_1_optimizer.html" title="ffnn::optimizer::Optimizer\l\&lt; layer::SparselyConnected\l\&lt; ValueType, InputsAtCompileTime,\l OutputsAtCompileTime \&gt; \&gt;" alt="" coords="5,5,240,75"/></map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:a87c420b734238a0c01d9928d224c649a"><td class="memItemLeft" align="right" valign="top">typedef <br class="typebreak"/>
<a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a><br class="typebreak"/>
&lt; ValueType, <br class="typebreak"/>
InputsAtCompileTime, <br class="typebreak"/>
OutputsAtCompileTime &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a87c420b734238a0c01d9928d224c649a">LayerType</a></td></tr>
<tr class="memdesc:a87c420b734238a0c01d9928d224c649a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Layer type standardization.  <a href="#a87c420b734238a0c01d9928d224c649a">More...</a><br/></td></tr>
<tr class="separator:a87c420b734238a0c01d9928d224c649a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adec062ac850983eca0cce2f84342f8fc"><td class="memItemLeft" align="right" valign="top">typedef <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html#abe2b75254f39c0bec9f02b2e906e7919">LayerType::ScalarType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#adec062ac850983eca0cce2f84342f8fc">ScalarType</a></td></tr>
<tr class="memdesc:adec062ac850983eca0cce2f84342f8fc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Scalar type standardization.  <a href="#adec062ac850983eca0cce2f84342f8fc">More...</a><br/></td></tr>
<tr class="separator:adec062ac850983eca0cce2f84342f8fc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a98715d1de7ba21998f64ec8e80051858"><td class="memItemLeft" align="right" valign="top">typedef <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html#a86b75c2723c1f8b6771224257f5eb1c1">LayerType::SizeType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a98715d1de7ba21998f64ec8e80051858">SizeType</a></td></tr>
<tr class="memdesc:a98715d1de7ba21998f64ec8e80051858"><td class="mdescLeft">&#160;</td><td class="mdescRight">Size type standardization.  <a href="#a98715d1de7ba21998f64ec8e80051858">More...</a><br/></td></tr>
<tr class="separator:a98715d1de7ba21998f64ec8e80051858"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a06fa3b5a9d654609c0d90dcc09382e38"><td class="memItemLeft" align="right" valign="top">typedef <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html#ad90fd9b4c687e4dc515cf8ca2796043c">LayerType::InputBlockType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a06fa3b5a9d654609c0d90dcc09382e38">InputBlockType</a></td></tr>
<tr class="memdesc:a06fa3b5a9d654609c0d90dcc09382e38"><td class="mdescLeft">&#160;</td><td class="mdescRight">Matrix type standardization.  <a href="#a06fa3b5a9d654609c0d90dcc09382e38">More...</a><br/></td></tr>
<tr class="separator:a06fa3b5a9d654609c0d90dcc09382e38"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3398102cd38960d104d31c868ecd9c06"><td class="memItemLeft" align="right" valign="top">typedef <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html#aacf4fb49a3f57aba90e55d8d3c63cf45">LayerType::OutputBlockType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a3398102cd38960d104d31c868ecd9c06">OutputBlockType</a></td></tr>
<tr class="memdesc:a3398102cd38960d104d31c868ecd9c06"><td class="mdescLeft">&#160;</td><td class="mdescRight">Matrix type standardization.  <a href="#a3398102cd38960d104d31c868ecd9c06">More...</a><br/></td></tr>
<tr class="separator:a3398102cd38960d104d31c868ecd9c06"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a83473b9494908577009ea7edf1de1dfd"><td class="memItemLeft" align="right" valign="top">typedef <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html#ad2d566cbb6c54c8723d79737075b4a00">LayerType::BiasVectorType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a83473b9494908577009ea7edf1de1dfd">BiasVectorType</a></td></tr>
<tr class="memdesc:a83473b9494908577009ea7edf1de1dfd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Bia vector type standardization.  <a href="#a83473b9494908577009ea7edf1de1dfd">More...</a><br/></td></tr>
<tr class="separator:a83473b9494908577009ea7edf1de1dfd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac103d3f1c0095e1a195238254271ce1"><td class="memItemLeft" align="right" valign="top">typedef <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html#acafafa368b81042965eed9607cad2dbd">LayerType::WeightMatrixType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#aac103d3f1c0095e1a195238254271ce1">WeightMatrixType</a></td></tr>
<tr class="memdesc:aac103d3f1c0095e1a195238254271ce1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Input-output weight matrix.  <a href="#aac103d3f1c0095e1a195238254271ce1">More...</a><br/></td></tr>
<tr class="separator:aac103d3f1c0095e1a195238254271ce1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_types_classffnn_1_1optimizer_1_1_optimizer"><td colspan="2" onclick="javascript:toggleInherit('pub_types_classffnn_1_1optimizer_1_1_optimizer')"><img src="closed.png" alt="-"/>&#160;Public Types inherited from <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html">ffnn::optimizer::Optimizer&lt; layer::SparselyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;</a></td></tr>
<tr class="memitem:ac03e7181934bf0c12a97fc67a60484ab inherit pub_types_classffnn_1_1optimizer_1_1_optimizer"><td class="memItemLeft" align="right" valign="top">typedef boost::shared_ptr<br class="typebreak"/>
&lt; <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html">Optimizer</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#ac03e7181934bf0c12a97fc67a60484ab">Ptr</a></td></tr>
<tr class="memdesc:ac03e7181934bf0c12a97fc67a60484ab inherit pub_types_classffnn_1_1optimizer_1_1_optimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Shared resource standardization.  <a href="#ac03e7181934bf0c12a97fc67a60484ab">More...</a><br/></td></tr>
<tr class="separator:ac03e7181934bf0c12a97fc67a60484ab inherit pub_types_classffnn_1_1optimizer_1_1_optimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d62c55f6f830e993ffe801fb17a1c3a inherit pub_types_classffnn_1_1optimizer_1_1_optimizer"><td class="memItemLeft" align="right" valign="top">typedef boost::shared_ptr<br class="typebreak"/>
&lt; const <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html">Optimizer</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a5d62c55f6f830e993ffe801fb17a1c3a">ConstPtr</a></td></tr>
<tr class="memdesc:a5d62c55f6f830e993ffe801fb17a1c3a inherit pub_types_classffnn_1_1optimizer_1_1_optimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constant shared resource standardization.  <a href="#a5d62c55f6f830e993ffe801fb17a1c3a">More...</a><br/></td></tr>
<tr class="separator:a5d62c55f6f830e993ffe801fb17a1c3a inherit pub_types_classffnn_1_1optimizer_1_1_optimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a9b0eb4e3cf8ba0d29b6625a3cd063273"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a9b0eb4e3cf8ba0d29b6625a3cd063273">GradientDescent</a> (<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#adec062ac850983eca0cce2f84342f8fc">ScalarType</a> lr)</td></tr>
<tr class="memdesc:a9b0eb4e3cf8ba0d29b6625a3cd063273"><td class="mdescLeft">&#160;</td><td class="mdescRight">Setup constructor.  <a href="#a9b0eb4e3cf8ba0d29b6625a3cd063273">More...</a><br/></td></tr>
<tr class="separator:a9b0eb4e3cf8ba0d29b6625a3cd063273"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2df4cb253c287efa26fae8d7580d01e9"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a2df4cb253c287efa26fae8d7580d01e9">~GradientDescent</a> ()</td></tr>
<tr class="separator:a2df4cb253c287efa26fae8d7580d01e9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac3fa00e4febe86906ff6045fe77777b0"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#ac3fa00e4febe86906ff6045fe77777b0">initialize</a> (<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a87c420b734238a0c01d9928d224c649a">LayerType</a> &amp;layer)</td></tr>
<tr class="memdesc:ac3fa00e4febe86906ff6045fe77777b0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initializes the <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html" title="A layer-wise optimizer visitor. ">Optimizer</a>.  <a href="#ac3fa00e4febe86906ff6045fe77777b0">More...</a><br/></td></tr>
<tr class="separator:ac3fa00e4febe86906ff6045fe77777b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61e4190921d10b1ec15f0a710b12df22"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a61e4190921d10b1ec15f0a710b12df22">reset</a> (<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a87c420b734238a0c01d9928d224c649a">LayerType</a> &amp;layer)</td></tr>
<tr class="memdesc:a61e4190921d10b1ec15f0a710b12df22"><td class="mdescLeft">&#160;</td><td class="mdescRight">Resetrs persistent <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html" title="A layer-wise optimizer visitor. ">Optimizer</a> states.  <a href="#a61e4190921d10b1ec15f0a710b12df22">More...</a><br/></td></tr>
<tr class="separator:a61e4190921d10b1ec15f0a710b12df22"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7e9882cd69c5d4ee64f5614614e9d96c"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a7e9882cd69c5d4ee64f5614614e9d96c">forward</a> (<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a87c420b734238a0c01d9928d224c649a">LayerType</a> &amp;layer)</td></tr>
<tr class="memdesc:a7e9882cd69c5d4ee64f5614614e9d96c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes one forward optimization update step.  <a href="#a7e9882cd69c5d4ee64f5614614e9d96c">More...</a><br/></td></tr>
<tr class="separator:a7e9882cd69c5d4ee64f5614614e9d96c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a21e3b66b2d83b356b4534cf6d789fa18"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a21e3b66b2d83b356b4534cf6d789fa18">backward</a> (<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a87c420b734238a0c01d9928d224c649a">LayerType</a> &amp;layer)</td></tr>
<tr class="memdesc:a21e3b66b2d83b356b4534cf6d789fa18"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes optimization step during backward propogation.  <a href="#a21e3b66b2d83b356b4534cf6d789fa18">More...</a><br/></td></tr>
<tr class="separator:a21e3b66b2d83b356b4534cf6d789fa18"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada280929e93a2d12f0bc21e9077e75a1"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#ada280929e93a2d12f0bc21e9077e75a1">update</a> (<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a87c420b734238a0c01d9928d224c649a">LayerType</a> &amp;layer)</td></tr>
<tr class="memdesc:ada280929e93a2d12f0bc21e9077e75a1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Applies optimization update.  <a href="#ada280929e93a2d12f0bc21e9077e75a1">More...</a><br/></td></tr>
<tr class="separator:ada280929e93a2d12f0bc21e9077e75a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classffnn_1_1optimizer_1_1_optimizer')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html">ffnn::optimizer::Optimizer&lt; layer::SparselyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;</a></td></tr>
<tr class="memitem:a5daf7f0191df7c672247e0d5a25fbafa inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a5daf7f0191df7c672247e0d5a25fbafa">Optimizer</a> (const std::string &amp;<a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a9c472d1e2ef75decdae1cf2db7582582">name</a>)</td></tr>
<tr class="memdesc:a5daf7f0191df7c672247e0d5a25fbafa inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Naming constructor.  <a href="#a5daf7f0191df7c672247e0d5a25fbafa">More...</a><br/></td></tr>
<tr class="separator:a5daf7f0191df7c672247e0d5a25fbafa inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad16c1cab142fcc9542da0ef98df75f47 inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#ad16c1cab142fcc9542da0ef98df75f47">~Optimizer</a> ()</td></tr>
<tr class="separator:ad16c1cab142fcc9542da0ef98df75f47 inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c472d1e2ef75decdae1cf2db7582582 inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memItemLeft" align="right" valign="top">const std::string &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a9c472d1e2ef75decdae1cf2db7582582">name</a> () const</td></tr>
<tr class="memdesc:a9c472d1e2ef75decdae1cf2db7582582 inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Exposes name of the optimizer.  <a href="#a9c472d1e2ef75decdae1cf2db7582582">More...</a><br/></td></tr>
<tr class="separator:a9c472d1e2ef75decdae1cf2db7582582 inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9aa028897eed9617b6439e1ea56a1ee inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#ab9aa028897eed9617b6439e1ea56a1ee">setName</a> (const std::string &amp;<a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a9c472d1e2ef75decdae1cf2db7582582">name</a>)</td></tr>
<tr class="memdesc:ab9aa028897eed9617b6439e1ea56a1ee inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets name of the optimizer.  <a href="#ab9aa028897eed9617b6439e1ea56a1ee">More...</a><br/></td></tr>
<tr class="separator:ab9aa028897eed9617b6439e1ea56a1ee inherit pub_methods_classffnn_1_1optimizer_1_1_optimizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a6e6729a1b56899a8e64cacff38e20bf9"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#adec062ac850983eca0cce2f84342f8fc">ScalarType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a6e6729a1b56899a8e64cacff38e20bf9">lr_</a></td></tr>
<tr class="memdesc:a6e6729a1b56899a8e64cacff38e20bf9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Learning rate.  <a href="#a6e6729a1b56899a8e64cacff38e20bf9">More...</a><br/></td></tr>
<tr class="separator:a6e6729a1b56899a8e64cacff38e20bf9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a105f65dc92c783222f228fed80c52fda"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#aac103d3f1c0095e1a195238254271ce1">WeightMatrixType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a105f65dc92c783222f228fed80c52fda">weight_gradient_</a></td></tr>
<tr class="memdesc:a105f65dc92c783222f228fed80c52fda"><td class="mdescLeft">&#160;</td><td class="mdescRight">Weight matrix delta.  <a href="#a105f65dc92c783222f228fed80c52fda">More...</a><br/></td></tr>
<tr class="separator:a105f65dc92c783222f228fed80c52fda"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38013045946f2a6d8a30445c9048654f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a83473b9494908577009ea7edf1de1dfd">BiasVectorType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a38013045946f2a6d8a30445c9048654f">bias_gradient_</a></td></tr>
<tr class="memdesc:a38013045946f2a6d8a30445c9048654f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Total bias vector delta.  <a href="#a38013045946f2a6d8a30445c9048654f">More...</a><br/></td></tr>
<tr class="separator:a38013045946f2a6d8a30445c9048654f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acce1f255ec414b8eddef1429398bccce"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a06fa3b5a9d654609c0d90dcc09382e38">InputBlockType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#acce1f255ec414b8eddef1429398bccce">prev_input_</a></td></tr>
<tr class="memdesc:acce1f255ec414b8eddef1429398bccce"><td class="mdescLeft">&#160;</td><td class="mdescRight">Previous input.  <a href="#acce1f255ec414b8eddef1429398bccce">More...</a><br/></td></tr>
<tr class="separator:acce1f255ec414b8eddef1429398bccce"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Member Typedef Documentation</h2>
<a class="anchor" id="a83473b9494908577009ea7edf1de1dfd"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html#ad2d566cbb6c54c8723d79737075b4a00">LayerType::BiasVectorType</a> <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a83473b9494908577009ea7edf1de1dfd">BiasVectorType</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Bia vector type standardization. </p>

</div>
</div>
<a class="anchor" id="a06fa3b5a9d654609c0d90dcc09382e38"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html#ad90fd9b4c687e4dc515cf8ca2796043c">LayerType::InputBlockType</a> <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a06fa3b5a9d654609c0d90dcc09382e38">InputBlockType</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Matrix type standardization. </p>

</div>
</div>
<a class="anchor" id="a87c420b734238a0c01d9928d224c649a"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt;ValueType, InputsAtCompileTime, OutputsAtCompileTime&gt; <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a87c420b734238a0c01d9928d224c649a">LayerType</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Layer type standardization. </p>

</div>
</div>
<a class="anchor" id="a3398102cd38960d104d31c868ecd9c06"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html#aacf4fb49a3f57aba90e55d8d3c63cf45">LayerType::OutputBlockType</a> <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a3398102cd38960d104d31c868ecd9c06">OutputBlockType</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Matrix type standardization. </p>

</div>
</div>
<a class="anchor" id="adec062ac850983eca0cce2f84342f8fc"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html#abe2b75254f39c0bec9f02b2e906e7919">LayerType::ScalarType</a> <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#adec062ac850983eca0cce2f84342f8fc">ScalarType</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Scalar type standardization. </p>

</div>
</div>
<a class="anchor" id="a98715d1de7ba21998f64ec8e80051858"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html#a86b75c2723c1f8b6771224257f5eb1c1">LayerType::SizeType</a> <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a98715d1de7ba21998f64ec8e80051858">SizeType</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Size type standardization. </p>

</div>
</div>
<a class="anchor" id="aac103d3f1c0095e1a195238254271ce1"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html#acafafa368b81042965eed9607cad2dbd">LayerType::WeightMatrixType</a> <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#aac103d3f1c0095e1a195238254271ce1">WeightMatrixType</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Input-output weight matrix. </p>

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a class="anchor" id="a9b0eb4e3cf8ba0d29b6625a3cd063273"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">GradientDescent</a> </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#adec062ac850983eca0cce2f84342f8fc">ScalarType</a>&#160;</td>
          <td class="paramname"><em>lr</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">explicit</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Setup constructor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">lr</td><td>Learning rate </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a2df4cb253c287efa26fae8d7580d01e9"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::~<a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">GradientDescent</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a class="anchor" id="a21e3b66b2d83b356b4534cf6d789fa18"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::backward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a87c420b734238a0c01d9928d224c649a">LayerType</a> &amp;&#160;</td>
          <td class="paramname"><em>layer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes optimization step during backward propogation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">layer</td><td>Layer to optimize </td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">true</td><td>if optimization setp was successful </td></tr>
    <tr><td class="paramname">false</td><td>otherwise </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#ab1f9b1cae01f93f53ecf7119bedb6369">ffnn::optimizer::Optimizer&lt; layer::SparselyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;</a>.</p>

<p><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_a21e3b66b2d83b356b4534cf6d789fa18_cgraph.png" border="0" usemap="#classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_a21e3b66b2d83b356b4534cf6d789fa18_cgraph" alt=""/></div>
<map name="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_a21e3b66b2d83b356b4534cf6d789fa18_cgraph" id="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_a21e3b66b2d83b356b4534cf6d789fa18_cgraph">
<area shape="rect" id="node2" href="classffnn_1_1layer_1_1internal_1_1_interface.html#a67cf9f89a90eadca6f9ec82dd66bd940" title="Returns true if layer has been initialized. " alt="" coords="304,5,459,46"/><area shape="rect" id="node3" href="structffnn_1_1layer_1_1internal_1_1_dimensions.html#a55225c7e571ffb20efc454767bc598e1" title="ffnn::layer::internal\l::Dimensions::size" alt="" coords="316,70,447,111"/></map>
</div>
</p>

</div>
</div>
<a class="anchor" id="a7e9882cd69c5d4ee64f5614614e9d96c"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::forward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a87c420b734238a0c01d9928d224c649a">LayerType</a> &amp;&#160;</td>
          <td class="paramname"><em>layer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes one forward optimization update step. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">layer</td><td>Layer to optimize </td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">true</td><td>if optimization setp was successful </td></tr>
    <tr><td class="paramname">false</td><td>otherwise </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a80505cfdeba0a3c8d1db19a2821613f2">ffnn::optimizer::Optimizer&lt; layer::SparselyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;</a>.</p>

<p><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_a7e9882cd69c5d4ee64f5614614e9d96c_cgraph.png" border="0" usemap="#classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_a7e9882cd69c5d4ee64f5614614e9d96c_cgraph" alt=""/></div>
<map name="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_a7e9882cd69c5d4ee64f5614614e9d96c_cgraph" id="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_a7e9882cd69c5d4ee64f5614614e9d96c_cgraph">
<area shape="rect" id="node2" href="classffnn_1_1layer_1_1internal_1_1_interface.html#a67cf9f89a90eadca6f9ec82dd66bd940" title="Returns true if layer has been initialized. " alt="" coords="291,19,445,61"/></map>
</div>
</p>

</div>
</div>
<a class="anchor" id="ac3fa00e4febe86906ff6045fe77777b0"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::initialize </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a87c420b734238a0c01d9928d224c649a">LayerType</a> &amp;&#160;</td>
          <td class="paramname"><em>layer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Initializes the <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html" title="A layer-wise optimizer visitor. ">Optimizer</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">layer</td><td>Layer to optimize </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a4302b66ba9b013ae4833eca235ff306a">ffnn::optimizer::Optimizer&lt; layer::SparselyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;</a>.</p>

<p>Reimplemented in <a class="el" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_sparsely_connected_3_01_value_type_00_01_inputs_at5101e46d32858ec2169acdeede08d723.html#a3529c6f6fb1befc882cc3ae17c00ba5a">ffnn::optimizer::Adam&lt; layer::SparselyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;</a>.</p>

<p><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_ac3fa00e4febe86906ff6045fe77777b0_cgraph.png" border="0" usemap="#classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_ac3fa00e4febe86906ff6045fe77777b0_cgraph" alt=""/></div>
<map name="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_ac3fa00e4febe86906ff6045fe77777b0_cgraph" id="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_ac3fa00e4febe86906ff6045fe77777b0_cgraph">
<area shape="rect" id="node2" href="classffnn_1_1layer_1_1internal_1_1_interface.html#a67cf9f89a90eadca6f9ec82dd66bd940" title="Returns true if layer has been initialized. " alt="" coords="296,5,451,46"/><area shape="rect" id="node3" href="structffnn_1_1layer_1_1internal_1_1_dimensions.html#a55225c7e571ffb20efc454767bc598e1" title="ffnn::layer::internal\l::Dimensions::size" alt="" coords="308,70,439,111"/></map>
</div>
</p>

</div>
</div>
<a class="anchor" id="a61e4190921d10b1ec15f0a710b12df22"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::reset </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a87c420b734238a0c01d9928d224c649a">LayerType</a> &amp;&#160;</td>
          <td class="paramname"><em>layer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Resetrs persistent <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html" title="A layer-wise optimizer visitor. ">Optimizer</a> states. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">layer</td><td>Layer to optimize </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#ade04e7582eb7b833713a9bd33e0e8346">ffnn::optimizer::Optimizer&lt; layer::SparselyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;</a>.</p>

<p><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_a61e4190921d10b1ec15f0a710b12df22_cgraph.png" border="0" usemap="#classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_a61e4190921d10b1ec15f0a710b12df22_cgraph" alt=""/></div>
<map name="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_a61e4190921d10b1ec15f0a710b12df22_cgraph" id="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_a61e4190921d10b1ec15f0a710b12df22_cgraph">
<area shape="rect" id="node2" href="structffnn_1_1layer_1_1internal_1_1_dimensions.html#a55225c7e571ffb20efc454767bc598e1" title="ffnn::layer::internal\l::Dimensions::size" alt="" coords="288,19,419,61"/></map>
</div>
</p>

</div>
</div>
<a class="anchor" id="ada280929e93a2d12f0bc21e9077e75a1"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::update </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a87c420b734238a0c01d9928d224c649a">LayerType</a> &amp;&#160;</td>
          <td class="paramname"><em>layer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Applies optimization update. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">layer</td><td>Layer to optimize </td></tr>
  </table>
  </dd>
</dl>
<dl class="retval"><dt>Return values</dt><dd>
  <table class="retval">
    <tr><td class="paramname">true</td><td>if optimization update was applied successfully </td></tr>
    <tr><td class="paramname">false</td><td>otherwise </td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="classffnn_1_1optimizer_1_1_optimizer.html#a7c88c2794446e03ccd41628bb25d7a07">ffnn::optimizer::Optimizer&lt; layer::SparselyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;</a>.</p>

<p>Reimplemented in <a class="el" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_sparsely_connected_3_01_value_type_00_01_inputs_at5101e46d32858ec2169acdeede08d723.html#aaa3b2eb55a9d80d51330c132df65214b">ffnn::optimizer::Adam&lt; layer::SparselyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;</a>.</p>

<p><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_ada280929e93a2d12f0bc21e9077e75a1_cgraph.png" border="0" usemap="#classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_ada280929e93a2d12f0bc21e9077e75a1_cgraph" alt=""/></div>
<map name="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_ada280929e93a2d12f0bc21e9077e75a1_cgraph" id="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf_ada280929e93a2d12f0bc21e9077e75a1_cgraph">
<area shape="rect" id="node2" href="classffnn_1_1layer_1_1internal_1_1_interface.html#a67cf9f89a90eadca6f9ec82dd66bd940" title="Returns true if layer has been initialized. " alt="" coords="288,19,443,61"/></map>
</div>
</p>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a class="anchor" id="a38013045946f2a6d8a30445c9048654f"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a83473b9494908577009ea7edf1de1dfd">BiasVectorType</a> <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::bias_gradient_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Total bias vector delta. </p>

</div>
</div>
<a class="anchor" id="a6e6729a1b56899a8e64cacff38e20bf9"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#adec062ac850983eca0cce2f84342f8fc">ScalarType</a> <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::lr_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Learning rate. </p>

</div>
</div>
<a class="anchor" id="acce1f255ec414b8eddef1429398bccce"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#a06fa3b5a9d654609c0d90dcc09382e38">InputBlockType</a> <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::prev_input_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Previous input. </p>

</div>
</div>
<a class="anchor" id="a105f65dc92c783222f228fed80c52fda"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent_3_01layer_1_1_sparsely_connected_3_01_value_type_00_e6c27913ab0d90f52f73031aa88c19bf.html#aac103d3f1c0095e1a195238254271ce1">WeightMatrixType</a> <a class="el" href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a>&lt; <a class="el" href="classffnn_1_1layer_1_1_sparsely_connected.html">layer::SparselyConnected</a>&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::weight_gradient_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Weight matrix delta. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/home/briancairl/packages/src/ffnn-cpp/ffnn/include/ffnn/optimizer/impl/gradient_descent/<a class="el" href="optimizer_2impl_2gradient__descent_2sparsely__connected_8hpp_source.html">sparsely_connected.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri May 5 2017 01:46:11 for FFNN by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.6
</small></address>
</body>
</html>
