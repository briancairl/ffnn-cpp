<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.6"/>
<title>FFNN: /home/briancairl/packages/src/ffnn-cpp/ffnn/include/ffnn/impl/optimizer/adam/fully_connected.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">FFNN
   &#160;<span id="projectnumber">0.0.1</span>
   </div>
   <div id="projectbrief">Fupa-funtime neural nets: a header-only neural network library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.6 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
      <li><a href="globals.html"><span>File&#160;Members</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(10)"><span class="SelectionMark">&#160;</span>Macros</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(11)"><span class="SelectionMark">&#160;</span>Groups</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_f1374a92efe2cc1f1014c2355d0648ea.html">ffnn</a></li><li class="navelem"><a class="el" href="dir_9f6bb62272f947f6d8714dfd4be1a938.html">impl</a></li><li class="navelem"><a class="el" href="dir_0346fed206a1c3e0ba93b1f75761b66e.html">optimizer</a></li><li class="navelem"><a class="el" href="dir_ec015fe4df94835f439c92fbe24d323e.html">adam</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">fully_connected.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="optimizer_2adam_2fully__connected_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;</div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment">// FFNN</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="assert_8h.html">ffnn/assert.h</a>&gt;</span></div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="logging_8h.html">ffnn/logging.h</a>&gt;</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="fully__connected_8h.html">ffnn/layer/fully_connected.h</a>&gt;</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#include &lt;ffnn/optimizer/impl/adam/adam_states.hpp&gt;</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;</div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="keyword">namespace </span>ffnn</div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;{</div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="keyword">namespace </span>optimizer</div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;{</div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="keyword">template</span>&lt;&gt;</div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> ValueType,</div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;         <a class="code" href="config_8h.html#aab5a5a098c5bf31f4176f4a141d2ef65">FFNN_SIZE_TYPE</a> InputsAtCompileTime,</div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;         <a class="code" href="config_8h.html#aab5a5a098c5bf31f4176f4a141d2ef65">FFNN_SIZE_TYPE</a> OutputsAtCompileTime&gt;</div>
<div class="line"><a name="l00020"></a><span class="lineno"><a class="line" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html">   20</a></span>&#160;<span class="keyword">class </span><a class="code" href="classffnn_1_1optimizer_1_1_adam.html">Adam</a>&lt;layer::FullyConnected&lt;ValueType, InputsAtCompileTime, OutputsAtCompileTime&gt;&gt;:</div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;  <span class="keyword">public</span> <a class="code" href="classffnn_1_1optimizer_1_1_gradient_descent.html">GradientDescent</a>&lt;layer::FullyConnected&lt;ValueType, InputsAtCompileTime, OutputsAtCompileTime&gt;&gt;</div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;{</div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="keyword">public</span>:</div>
<div class="line"><a name="l00025"></a><span class="lineno"><a class="line" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#ad82ece03afb695075874eaed356433d2">   25</a></span>&#160;  <span class="keyword">typedef</span> <span class="keyword">typename</span> <a class="code" href="classffnn_1_1layer_1_1_fully_connected.html">layer::FullyConnected&lt;ValueType, InputsAtCompileTime, OutputsAtCompileTime&gt;</a> <a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#ad82ece03afb695075874eaed356433d2">LayerType</a>;</div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;</div>
<div class="line"><a name="l00028"></a><span class="lineno"><a class="line" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#aa039b3368a2997e3437a32da6ef4a373">   28</a></span>&#160;  <span class="keyword">typedef</span> <a class="code" href="classffnn_1_1optimizer_1_1_gradient_descent.html">GradientDescent&lt;LayerType&gt;</a> <a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#aa039b3368a2997e3437a32da6ef4a373">Base</a>;</div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;</div>
<div class="line"><a name="l00031"></a><span class="lineno"><a class="line" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a966519516e8af4fcb6d58840a7d1d12a">   31</a></span>&#160;  <span class="keyword">typedef</span> <span class="keyword">typename</span> LayerType::Scalar <a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a966519516e8af4fcb6d58840a7d1d12a">Scalar</a>;</div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;</div>
<div class="line"><a name="l00034"></a><span class="lineno"><a class="line" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a6bbc6e181e5a5192b7b5cc42e3172372">   34</a></span>&#160;  <span class="keyword">typedef</span> <span class="keyword">typename</span> LayerType::SizeType <a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a6bbc6e181e5a5192b7b5cc42e3172372">SizeType</a>;</div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;</div>
<div class="line"><a name="l00037"></a><span class="lineno"><a class="line" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a0f9a1a492d0763a6068fd01c3c8d705a">   37</a></span>&#160;  <span class="keyword">typedef</span> <span class="keyword">typename</span> LayerType::InputBlockType <a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a0f9a1a492d0763a6068fd01c3c8d705a">InputBlockType</a>;</div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;</div>
<div class="line"><a name="l00040"></a><span class="lineno"><a class="line" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a6b5ddc1adcb4bbc052bda25ac5ecef0b">   40</a></span>&#160;  <span class="keyword">typedef</span> <span class="keyword">typename</span> LayerType::OutputBlockType <a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a6b5ddc1adcb4bbc052bda25ac5ecef0b">OutputBlockType</a>;</div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;</div>
<div class="line"><a name="l00043"></a><span class="lineno"><a class="line" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#aac2f4d3e444074ab554d2a0a45ba1daf">   43</a></span>&#160;  <span class="keyword">typedef</span> <span class="keyword">typename</span> LayerType::WeightMatrixType <a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#aac2f4d3e444074ab554d2a0a45ba1daf">WeightMatrixType</a>;</div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;</div>
<div class="line"><a name="l00046"></a><span class="lineno"><a class="line" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#ac7a23bb92a19d1155a19feefbb5d366d">   46</a></span>&#160;  <span class="keyword">typedef</span> <span class="keyword">typename</span> LayerType::BiasVectorType <a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#ac7a23bb92a19d1155a19feefbb5d366d">BiasVectorType</a>;</div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;  <span class="keyword">explicit</span></div>
<div class="line"><a name="l00053"></a><span class="lineno"><a class="line" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#aa38355640423e04dc7522fae2c8e5449">   53</a></span>&#160;  <a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#aa38355640423e04dc7522fae2c8e5449">Adam</a>(<a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a966519516e8af4fcb6d58840a7d1d12a">Scalar</a> lr, <a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a966519516e8af4fcb6d58840a7d1d12a">Scalar</a> beta1 = 0.9, <a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a966519516e8af4fcb6d58840a7d1d12a">Scalar</a> beta2 = 0.999, <a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a966519516e8af4fcb6d58840a7d1d12a">Scalar</a> eps = 1e-8) :</div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;    <a class="code" href="classffnn_1_1optimizer_1_1_gradient_descent.html">Base</a>(lr),</div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;    gradient_states_(beta1, beta2, eps)</div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;  {</div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;    Base::setName(<span class="stringliteral">&quot;Adam&quot;</span>);</div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;    <a class="code" href="assert_8h.html#a0dd452510e5d75d0f71f52ed14143c40">FFNN_ASSERT_MSG</a>(beta1 &gt; 0 &amp;&amp; beta1 &lt; 1, <span class="stringliteral">&quot;&#39;beta1&#39; should be in the range (0, 1).&quot;</span>);</div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;    <a class="code" href="assert_8h.html#a0dd452510e5d75d0f71f52ed14143c40">FFNN_ASSERT_MSG</a>(beta2 &gt; 0 &amp;&amp; beta2 &lt; 1, <span class="stringliteral">&quot;&#39;beta2&#39; should be in the range (0, 1).&quot;</span>);</div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;    <a class="code" href="assert_8h.html#a0dd452510e5d75d0f71f52ed14143c40">FFNN_ASSERT_MSG</a>(eps &gt; 0, <span class="stringliteral">&quot;Epsilon should be &gt; 0.&quot;</span>);</div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;  }</div>
<div class="line"><a name="l00062"></a><span class="lineno"><a class="line" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#aa5cab60a5d10331e2e02ea932c58b2d0">   62</a></span>&#160;  <span class="keyword">virtual</span> <a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#aa5cab60a5d10331e2e02ea932c58b2d0">~Adam</a>() {}</div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;</div>
<div class="line"><a name="l00068"></a><span class="lineno"><a class="line" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#aa67f949f7a1228c221d06b1b1e03c28b">   68</a></span>&#160;  <span class="keywordtype">void</span> <a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#aa67f949f7a1228c221d06b1b1e03c28b">initialize</a>(<a class="code" href="classffnn_1_1layer_1_1_fully_connected.html">LayerType</a>&amp; layer)</div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;  {</div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    Base::initialize(layer);</div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;</div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    <span class="comment">// Reset states</span></div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;    weight_gradient_states_.initialize(layer.output_shape_.size(), layer.input_shape_.size());</div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;    bias_gradient_states_.initialize(layer.output_shape_.size(), layer.input_shape_.size());</div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;  }</div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;</div>
<div class="line"><a name="l00083"></a><span class="lineno"><a class="line" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#ad42586e39195fc9a72057f20b657f8be">   83</a></span>&#160;  <span class="keywordtype">bool</span> <a class="code" href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#ad42586e39195fc9a72057f20b657f8be">update</a>(<a class="code" href="classffnn_1_1layer_1_1_fully_connected.html">LayerType</a>&amp; layer)</div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;  {</div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;    <a class="code" href="assert_8h.html#a0dd452510e5d75d0f71f52ed14143c40">FFNN_ASSERT_MSG</a>(layer.isInitialized(), <span class="stringliteral">&quot;Layer to optimize is not initialized.&quot;</span>);</div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;</div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;    <span class="comment">// Update gradients</span></div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;    weight_gradient_states_.update(Base::weight_gradient_, beta1_, beta2_, epsilon_);</div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;    bias_gradient_states_.update(Base::bias_gradient_, beta1_, beta2_, epsilon_);</div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;</div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;    <span class="comment">// Reinitialize optimizer</span></div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;    Base::update(layer);</div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;  }</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;<span class="keyword">private</span>:</div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;  <span class="keyword">const</span> Scalar beta1_;</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;  <span class="keyword">const</span> Scalar beta2_;</div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;</div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;  <span class="keyword">const</span> Scalar epsilon_;</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;</div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;  <a class="code" href="classffnn_1_1optimizer_1_1_adam_states.html">AdamStates&lt;WeightMatrixType&gt;</a> gradient_states_;</div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;};</div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;}  <span class="comment">// namespace optimizer</span></div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;}  <span class="comment">// namespace ffnn</span></div>
<div class="ttc" id="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd_html_ad42586e39195fc9a72057f20b657f8be"><div class="ttname"><a href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#ad42586e39195fc9a72057f20b657f8be">ffnn::optimizer::Adam&lt; layer::FullyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::update</a></div><div class="ttdeci">bool update(LayerType &amp;layer)</div><div class="ttdoc">Applies optimization update. </div><div class="ttdef"><b>Definition:</b> fully_connected.hpp:83</div></div>
<div class="ttc" id="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd_html_aac2f4d3e444074ab554d2a0a45ba1daf"><div class="ttname"><a href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#aac2f4d3e444074ab554d2a0a45ba1daf">ffnn::optimizer::Adam&lt; layer::FullyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::WeightMatrixType</a></div><div class="ttdeci">LayerType::WeightMatrixType WeightMatrixType</div><div class="ttdoc">Input-output weight matrix. </div><div class="ttdef"><b>Definition:</b> fully_connected.hpp:43</div></div>
<div class="ttc" id="config_8h_html_aab5a5a098c5bf31f4176f4a141d2ef65"><div class="ttname"><a href="config_8h.html#aab5a5a098c5bf31f4176f4a141d2ef65">FFNN_SIZE_TYPE</a></div><div class="ttdeci">#define FFNN_SIZE_TYPE</div><div class="ttdef"><b>Definition:</b> config.h:38</div></div>
<div class="ttc" id="classffnn_1_1layer_1_1_fully_connected_html"><div class="ttname"><a href="classffnn_1_1layer_1_1_fully_connected.html">ffnn::layer::FullyConnected</a></div><div class="ttdoc">A fully-connected layer. </div><div class="ttdef"><b>Definition:</b> fully_connected.h:28</div></div>
<div class="ttc" id="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd_html_aa039b3368a2997e3437a32da6ef4a373"><div class="ttname"><a href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#aa039b3368a2997e3437a32da6ef4a373">ffnn::optimizer::Adam&lt; layer::FullyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::Base</a></div><div class="ttdeci">GradientDescent&lt; LayerType &gt; Base</div><div class="ttdoc">Base type standardization. </div><div class="ttdef"><b>Definition:</b> fully_connected.hpp:28</div></div>
<div class="ttc" id="classffnn_1_1optimizer_1_1_adam_html"><div class="ttname"><a href="classffnn_1_1optimizer_1_1_adam.html">ffnn::optimizer::Adam</a></div><div class="ttdef"><b>Definition:</b> fwd.h:17</div></div>
<div class="ttc" id="fully__connected_8h_html"><div class="ttname"><a href="fully__connected_8h.html">fully_connected.h</a></div></div>
<div class="ttc" id="logging_8h_html"><div class="ttname"><a href="logging_8h.html">logging.h</a></div></div>
<div class="ttc" id="classffnn_1_1optimizer_1_1_gradient_descent_html"><div class="ttname"><a href="classffnn_1_1optimizer_1_1_gradient_descent.html">ffnn::optimizer::GradientDescent</a></div><div class="ttdef"><b>Definition:</b> fwd.h:18</div></div>
<div class="ttc" id="assert_8h_html_a0dd452510e5d75d0f71f52ed14143c40"><div class="ttname"><a href="assert_8h.html#a0dd452510e5d75d0f71f52ed14143c40">FFNN_ASSERT_MSG</a></div><div class="ttdeci">#define FFNN_ASSERT_MSG(cond, msg)</div><div class="ttdef"><b>Definition:</b> assert.h:24</div></div>
<div class="ttc" id="assert_8h_html"><div class="ttname"><a href="assert_8h.html">assert.h</a></div></div>
<div class="ttc" id="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd_html_aa38355640423e04dc7522fae2c8e5449"><div class="ttname"><a href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#aa38355640423e04dc7522fae2c8e5449">ffnn::optimizer::Adam&lt; layer::FullyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::Adam</a></div><div class="ttdeci">Adam(Scalar lr, Scalar beta1=0.9, Scalar beta2=0.999, Scalar eps=1e-8)</div><div class="ttdoc">Setup constructor. </div><div class="ttdef"><b>Definition:</b> fully_connected.hpp:53</div></div>
<div class="ttc" id="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd_html_a6b5ddc1adcb4bbc052bda25ac5ecef0b"><div class="ttname"><a href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a6b5ddc1adcb4bbc052bda25ac5ecef0b">ffnn::optimizer::Adam&lt; layer::FullyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::OutputBlockType</a></div><div class="ttdeci">LayerType::OutputBlockType OutputBlockType</div><div class="ttdoc">Matrix type standardization. </div><div class="ttdef"><b>Definition:</b> fully_connected.hpp:40</div></div>
<div class="ttc" id="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd_html_a6bbc6e181e5a5192b7b5cc42e3172372"><div class="ttname"><a href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a6bbc6e181e5a5192b7b5cc42e3172372">ffnn::optimizer::Adam&lt; layer::FullyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::SizeType</a></div><div class="ttdeci">LayerType::SizeType SizeType</div><div class="ttdoc">Size type standardization. </div><div class="ttdef"><b>Definition:</b> fully_connected.hpp:34</div></div>
<div class="ttc" id="classffnn_1_1optimizer_1_1_adam_states_html"><div class="ttname"><a href="classffnn_1_1optimizer_1_1_adam_states.html">ffnn::optimizer::AdamStates&lt; WeightMatrixType &gt;</a></div></div>
<div class="ttc" id="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd_html_aa5cab60a5d10331e2e02ea932c58b2d0"><div class="ttname"><a href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#aa5cab60a5d10331e2e02ea932c58b2d0">ffnn::optimizer::Adam&lt; layer::FullyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::~Adam</a></div><div class="ttdeci">virtual ~Adam()</div><div class="ttdef"><b>Definition:</b> fully_connected.hpp:62</div></div>
<div class="ttc" id="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd_html_aa67f949f7a1228c221d06b1b1e03c28b"><div class="ttname"><a href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#aa67f949f7a1228c221d06b1b1e03c28b">ffnn::optimizer::Adam&lt; layer::FullyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::initialize</a></div><div class="ttdeci">void initialize(LayerType &amp;layer)</div><div class="ttdoc">Initializes the Optimizer. </div><div class="ttdef"><b>Definition:</b> fully_connected.hpp:68</div></div>
<div class="ttc" id="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd_html_ad82ece03afb695075874eaed356433d2"><div class="ttname"><a href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#ad82ece03afb695075874eaed356433d2">ffnn::optimizer::Adam&lt; layer::FullyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::LayerType</a></div><div class="ttdeci">layer::FullyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; LayerType</div><div class="ttdoc">Layer type standardization. </div><div class="ttdef"><b>Definition:</b> fully_connected.hpp:25</div></div>
<div class="ttc" id="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd_html_a966519516e8af4fcb6d58840a7d1d12a"><div class="ttname"><a href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a966519516e8af4fcb6d58840a7d1d12a">ffnn::optimizer::Adam&lt; layer::FullyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::Scalar</a></div><div class="ttdeci">LayerType::Scalar Scalar</div><div class="ttdoc">Scalar type standardization. </div><div class="ttdef"><b>Definition:</b> fully_connected.hpp:31</div></div>
<div class="ttc" id="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd_html_ac7a23bb92a19d1155a19feefbb5d366d"><div class="ttname"><a href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#ac7a23bb92a19d1155a19feefbb5d366d">ffnn::optimizer::Adam&lt; layer::FullyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::BiasVectorType</a></div><div class="ttdeci">LayerType::BiasVectorType BiasVectorType</div><div class="ttdoc">Bia vector type standardization. </div><div class="ttdef"><b>Definition:</b> fully_connected.hpp:46</div></div>
<div class="ttc" id="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd_html_a0f9a1a492d0763a6068fd01c3c8d705a"><div class="ttname"><a href="classffnn_1_1optimizer_1_1_adam_3_01layer_1_1_fully_connected_3_01_value_type_00_01_inputs_at_co08ce471fd3ee7441a350cc42cfd35bcd.html#a0f9a1a492d0763a6068fd01c3c8d705a">ffnn::optimizer::Adam&lt; layer::FullyConnected&lt; ValueType, InputsAtCompileTime, OutputsAtCompileTime &gt; &gt;::InputBlockType</a></div><div class="ttdeci">LayerType::InputBlockType InputBlockType</div><div class="ttdoc">Matrix type standardization. </div><div class="ttdef"><b>Definition:</b> fully_connected.hpp:37</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Thu Jun 8 2017 01:08:56 for FFNN by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.6
</small></address>
</body>
</html>
